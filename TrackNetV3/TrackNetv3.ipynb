{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2At3hmfpbrTW",
        "outputId": "6c62975e-0a4b-4396-9225-9251e05f19f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Installing dependencies...\n",
            "âœ… Dependencies installed.\n"
          ]
        }
      ],
      "source": [
        "# Install required packages\n",
        "print(\"ðŸš€ Installing dependencies...\")\n",
        "\n",
        "!pip -q install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip -q install opencv-python numpy matplotlib pillow scikit-image tqdm\n",
        "\n",
        "print(\"âœ… Dependencies installed.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the TrackNetV3 repo\n",
        "print(\"ðŸ“‚ Cloning TrackNetV3 repository...\")\n",
        "\n",
        "!git clone https://github.com/qaz812345/TrackNetV3.git\n",
        "%cd TrackNetV3\n",
        "\n",
        "print(\"âœ… Repo cloned.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "890Oy-RmdM2U",
        "outputId": "5ff2bd54-3828-4b12-b2af-cd8ebbaa50a4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“‚ Cloning TrackNetV3 repository...\n",
            "Cloning into 'TrackNetV3'...\n",
            "remote: Enumerating objects: 240, done.\u001b[K\n",
            "remote: Counting objects: 100% (111/111), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 240 (delta 99), reused 87 (delta 87), pack-reused 129 (from 1)\u001b[K\n",
            "Receiving objects: 100% (240/240), 2.82 MiB | 24.85 MiB/s, done.\n",
            "Resolving deltas: 100% (134/134), done.\n",
            "/content/TrackNetV3\n",
            "âœ… Repo cloned.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2uuWPVQ2qa5",
        "outputId": "8d3b4962-f4a6-4a83-828f-d2b0dcdfe4ad"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting dash==2.5.1 (from -r requirements.txt (line 1))\n",
            "  Downloading dash-2.5.1-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting numpy==1.22.4 (from -r requirements.txt (line 2))\n",
            "  Downloading numpy-1.22.4.zip (11.5 MB)\n",
            "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "  \n",
            "  \u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "  \u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "  \u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "  \n",
            "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n",
            "\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
            "\n",
            "\u001b[31mÃ—\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n",
            "\u001b[31mâ”‚\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
            "\u001b[31mâ•°â”€>\u001b[0m See above for output.\n",
            "\n",
            "\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ”½ Downloading checkpoints.zip from Google Drive link...\")\n",
        "\n",
        "!wget -O checkpoints.zip \"https://drive.usercontent.google.com/download?id=1CfzE87a0f6LhBp0kniSl1-89zaLCZ8cA&export=download&confirm=t\"\n",
        "print(\"âœ… Downloaded checkpoints.zip\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Km5f-7fedTBh",
        "outputId": "5313df33-0b03-4e5f-9ec1-c2622a4cf3b2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ”½ Downloading checkpoints.zip from Google Drive link...\n",
            "--2025-09-21 13:39:39--  https://drive.usercontent.google.com/download?id=1CfzE87a0f6LhBp0kniSl1-89zaLCZ8cA&export=download&confirm=t\n",
            "Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 173.194.212.132, 2607:f8b0:400c:c11::84\n",
            "Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|173.194.212.132|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 131653952 (126M) [application/octet-stream]\n",
            "Saving to: â€˜checkpoints.zipâ€™\n",
            "\n",
            "checkpoints.zip     100%[===================>] 125.55M   142MB/s    in 0.9s    \n",
            "\n",
            "2025-09-21 13:39:41 (142 MB/s) - â€˜checkpoints.zipâ€™ saved [131653952/131653952]\n",
            "\n",
            "âœ… Downloaded checkpoints.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ” Checking contents of 'ckpts/'...\")\n",
        "!ls -la ckpts/\n",
        "\n",
        "print(\"\\nðŸ” Checking contents of 'weights/'...\")\n",
        "!ls -la weights/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5uv8m3mgVSg",
        "outputId": "b9b3b0a0-60d8-400e-93d2-e5597822b797"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ” Checking contents of 'ckpts/'...\n",
            "total 139128\n",
            "drwxr-xr-x 2 root root      4096 Aug  8  2023 .\n",
            "drwxr-xr-x 8 root root      4096 Sep 21 13:40 ..\n",
            "-rw-r--r-- 1 root root   6264451 Aug  8  2023 InpaintNet_best.pt\n",
            "-rw-r--r-- 1 root root 136190877 Aug  8  2023 TrackNet_best.pt\n",
            "\n",
            "ðŸ” Checking contents of 'weights/'...\n",
            "total 8\n",
            "drwxr-xr-x 2 root root 4096 Sep 21 13:27 .\n",
            "drwxr-xr-x 8 root root 4096 Sep 21 13:40 ..\n",
            "-rw-r--r-- 1 root root    0 Sep 21 13:27 tracknet_weights.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"ðŸ§  Loading TrackNetV3 model architecture...\")\n",
        "\n",
        "%cd /content/TrackNetV3\n",
        "\n",
        "from model import TrackNet\n",
        "import torch\n",
        "\n",
        "# Initialize the model with correct input and output dimensions based on the error\n",
        "model = TrackNet(in_dim=27, out_dim=8)\n",
        "print(\"âœ… Model architecture loaded.\")\n",
        "\n",
        "# Load the checkpoint\n",
        "checkpoint_path = 'ckpts/TrackNet_best.pt'\n",
        "state_dict = torch.load(checkpoint_path, map_location='cpu')\n",
        "\n",
        "# Extract only the model state dictionary\n",
        "model_state_dict = state_dict['model']\n",
        "\n",
        "# Fix keys if they have 'module.' prefix (common in DataParallel models)\n",
        "model_state_dict = {k.replace('module.', ''): v for k, v in model_state_dict.items()}\n",
        "\n",
        "model.load_state_dict(model_state_dict)\n",
        "model.eval()\n",
        "\n",
        "print(\"âœ… Successfully loaded weights from ckpts/TrackNet_best.pt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_5iHlv3ig_3R",
        "outputId": "aab55338-e002-4350-914a-7c292d50f872"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§  Loading TrackNetV3 model architecture...\n",
            "/content/TrackNetV3\n",
            "âœ… Model architecture loaded.\n",
            "âœ… Successfully loaded weights from ckpts/TrackNet_best.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/TrackNetV3/predict.py\n",
        "# predict.py - Fixed for Colab Compatibility\n",
        "\n",
        "import os\n",
        "import argparse\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Assume these exist from the repo\n",
        "from test import predict_location, get_ensemble_weight, generate_inpaint_mask\n",
        "from dataset import Shuttlecock_Trajectory_Dataset, Video_IterableDataset\n",
        "from utils.general import get_model, write_pred_csv, write_pred_video, generate_frames, to_img_format, to_img\n",
        "\n",
        "# ðŸ”§ Constants (likely defined elsewhere â€” now added here)\n",
        "WIDTH = 640   # Input width for model\n",
        "HEIGHT = 360  # Input height for model\n",
        "COOR_TH = 0.01  # Threshold for coordinate validity\n",
        "\n",
        "# ðŸ› ï¸ Fix: Use XVID codec for reliable video output in Colab\n",
        "def create_video_writer(save_file, fps, w, h):\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'XVID')  # Works reliably in Colab\n",
        "    return cv2.VideoWriter(save_file, fourcc, fps, (w, h))\n",
        "\n",
        "\n",
        "def predict(indices, y_pred=None, c_pred=None, img_scaler=(1, 1)):\n",
        "    \"\"\" Predict coordinates from heatmap or inpainted coordinates. \"\"\"\n",
        "    pred_dict = {'Frame': [], 'X': [], 'Y': [], 'Visibility': []}\n",
        "\n",
        "    batch_size, seq_len = indices.shape[0], indices.shape[1]\n",
        "    indices = indices.detach().cpu().numpy() if torch.is_tensor(indices) else indices.numpy()\n",
        "\n",
        "    if y_pred is not None:\n",
        "        y_pred = (y_pred > 0.5).detach().cpu().numpy()\n",
        "        y_pred = to_img_format(y_pred)\n",
        "\n",
        "    if c_pred is not None:\n",
        "        c_pred = c_pred.detach().cpu().numpy()\n",
        "\n",
        "    prev_f_i = -1\n",
        "    for n in range(batch_size):\n",
        "        for f in range(seq_len):\n",
        "            f_i = indices[n][f][1]\n",
        "            if f_i != prev_f_i:\n",
        "                if c_pred is not None:\n",
        "                    c_p = c_pred[n][f]\n",
        "                    cx_pred = int(c_p[0] * WIDTH * img_scaler[0])\n",
        "                    cy_pred = int(c_p[1] * HEIGHT * img_scaler[1])\n",
        "                elif y_pred is not None:\n",
        "                    y_p = y_pred[n][f]\n",
        "                    bbox_pred = predict_location(to_img(y_p))\n",
        "                    cx_pred = int((bbox_pred[0] + bbox_pred[2] / 2) * img_scaler[0])\n",
        "                    cy_pred = int((bbox_pred[1] + bbox_pred[3] / 2) * img_scaler[1])\n",
        "                else:\n",
        "                    raise ValueError('Invalid input')\n",
        "\n",
        "                vis_pred = 0 if cx_pred == 0 and cy_pred == 0 else 1\n",
        "                pred_dict['Frame'].append(int(f_i))\n",
        "                pred_dict['X'].append(cx_pred)\n",
        "                pred_dict['Y'].append(cy_pred)\n",
        "                pred_dict['Visibility'].append(vis_pred)\n",
        "                prev_f_i = f_i\n",
        "            else:\n",
        "                break\n",
        "    return pred_dict\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument('--video_file', type=str, required=True, help='file path of the video')\n",
        "    parser.add_argument('--tracknet_file', type=str, required=True, help='file path of the TrackNet model checkpoint')\n",
        "    parser.add_argument('--inpaintnet_file', type=str, default='', help='file path of the InpaintNet model checkpoint')\n",
        "    parser.add_argument('--batch_size', type=int, default=1, help='batch size for inference (Colab-friendly)')\n",
        "    parser.add_argument('--eval_mode', type=str, default='weight', choices=['nonoverlap', 'average', 'weight'])\n",
        "    parser.add_argument('--max_sample_num', type=int, default=1800)\n",
        "    parser.add_argument('--video_range', type=str, default=None, help='start,end in seconds')\n",
        "    parser.add_argument('--save_dir', type=str, default='prediction', help='output directory')\n",
        "    parser.add_argument('--large_video', action='store_true', help='for long videos')\n",
        "    parser.add_argument('--output_video', action='store_true', help='generate output video')\n",
        "    parser.add_argument('--traj_len', type=int, default=8, help='length of trajectory trail')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # ðŸ”½ Force low num_workers to avoid Colab crash\n",
        "    num_workers = 0  # Was: args.batch_size if ... â†’ now safe\n",
        "\n",
        "    video_file = args.video_file\n",
        "    video_name = os.path.splitext(os.path.basename(video_file))[0]\n",
        "    video_range = [int(x) for x in args.video_range.split(',')] if args.video_range else None\n",
        "    large_video = args.large_video\n",
        "    save_dir = args.save_dir\n",
        "\n",
        "    out_csv_file = os.path.join(save_dir, f'{video_name}_ball.csv')\n",
        "    out_video_file = os.path.join(save_dir, f'{video_name}.avi')  # ðŸ”´ Use .avi for XVID\n",
        "\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Load models\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    tracknet_ckpt = torch.load(args.tracknet_file, map_location=device)\n",
        "    seq_len = tracknet_ckpt['param_dict']['seq_len']\n",
        "    bg_mode = tracknet_ckpt['param_dict']['bg_mode']\n",
        "\n",
        "    tracknet = get_model('TrackNet', seq_len, bg_mode).to(device)\n",
        "    tracknet.load_state_dict(tracknet_ckpt['model'])\n",
        "    tracknet.eval()\n",
        "\n",
        "    inpaintnet = None\n",
        "    if args.inpaintnet_file:\n",
        "        inpaintnet_ckpt = torch.load(args.inpaintnet_file, map_location=device)\n",
        "        inpaintnet = get_model('InpaintNet').to(device)\n",
        "        inpaintnet.load_state_dict(inpaintnet_ckpt['model'])\n",
        "        inpaintnet.eval()\n",
        "\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    cap.release()\n",
        "\n",
        "    w_scaler, h_scaler = w / WIDTH, h / HEIGHT\n",
        "    img_scaler = (w_scaler, h_scaler)\n",
        "\n",
        "    # Test on TrackNet\n",
        "    tracknet_pred_dict = {\n",
        "        'Frame': [], 'X': [], 'Y': [], 'Visibility': [], 'Inpaint_Mask': [],\n",
        "        'Img_scaler': (w_scaler, h_scaler), 'Img_shape': (w, h)\n",
        "    }\n",
        "\n",
        "    print(\"ðŸš€ Starting inference...\")\n",
        "\n",
        "    if args.eval_mode == 'nonoverlap':\n",
        "        if large_video:\n",
        "            dataset = Video_IterableDataset(\n",
        "                video_file, seq_len=seq_len, sliding_step=seq_len,\n",
        "                bg_mode=bg_mode, max_sample_num=args.max_sample_num,\n",
        "                video_range=video_range\n",
        "            )\n",
        "            data_loader = DataLoader(dataset, batch_size=args.batch_size, shuffle=False, drop_last=False)\n",
        "        else:\n",
        "            frame_list = generate_frames(video_file)\n",
        "            dataset = Shuttlecock_Trajectory_Dataset(\n",
        "                seq_len=seq_len, sliding_step=seq_len, data_mode='heatmap',\n",
        "                bg_mode=bg_mode, frame_arr=np.array(frame_list)[:, :, :, ::-1], padding=True\n",
        "            )\n",
        "            data_loader = DataLoader(\n",
        "                dataset, batch_size=args.batch_size, shuffle=False,\n",
        "                num_workers=num_workers, drop_last=False\n",
        "            )\n",
        "\n",
        "        for step, (i, x) in enumerate(tqdm(data_loader)):\n",
        "            x = x.float().to(device)\n",
        "            with torch.no_grad():\n",
        "                y_pred = tracknet(x).detach().cpu()\n",
        "            tmp_pred = predict(i, y_pred=y_pred, img_scaler=img_scaler)\n",
        "            for k in tmp_pred:\n",
        "                tracknet_pred_dict[k].extend(tmp_pred[k])\n",
        "\n",
        "    # Write CSV\n",
        "    pred_dict = tracknet_pred_dict.copy()\n",
        "    if inpaintnet is not None:\n",
        "        # InpaintNet logic can be added later\n",
        "        pass\n",
        "\n",
        "    write_pred_csv(pred_dict, save_file=out_csv_file)\n",
        "    print(f\"âœ… CSV saved: {out_csv_file}\")\n",
        "\n",
        "    # Write Video\n",
        "    if args.output_video:\n",
        "        print(\"ðŸŽ¬ Generating output video...\")\n",
        "        writer = create_video_writer(out_video_file, 30, w, h)\n",
        "        cap = cv2.VideoCapture(video_file)\n",
        "        frame_idx = 0\n",
        "        traj_points = []\n",
        "\n",
        "        while True:\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            # Find prediction for this frame\n",
        "            if frame_idx in pred_dict['Frame']:\n",
        "                idx = pred_dict['Frame'].index(frame_idx)\n",
        "                x_pos = pred_dict['X'][idx]\n",
        "                y_pos = pred_dict['Y'][idx]\n",
        "                visible = pred_dict['Visibility'][idx]\n",
        "\n",
        "                if visible:\n",
        "                    cv2.circle(frame, (x_pos, y_pos), 8, (0, 0, 255), -1)\n",
        "                    cv2.putText(frame, f'{frame_idx}', (x_pos + 10, y_pos),\n",
        "                                cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 0, 255), 2)\n",
        "                    traj_points.append((x_pos, y_pos))\n",
        "                else:\n",
        "                    traj_points.append(None)\n",
        "            else:\n",
        "                traj_points.append(None)\n",
        "\n",
        "            # Draw trajectory\n",
        "            for i in range(1, min(args.traj_len, len(traj_points))):\n",
        "                if traj_points[-i-1] and traj_points[-i]:\n",
        "                    cv2.line(frame, traj_points[-i-1], traj_points[-i], (0, 255, 0), 2)\n",
        "\n",
        "            writer.write(frame)\n",
        "            frame_idx += 1\n",
        "\n",
        "        cap.release()\n",
        "        writer.release()\n",
        "        print(f\"âœ… Video saved: {out_video_file}\")\n",
        "\n",
        "    print(\"ðŸŽ‰ Done.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYzlvfOt7Zov",
        "outputId": "dceb375e-e629-4479-e444-8778d6f3f187"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/TrackNetV3/predict.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/TrackNetV3\n",
        "\n",
        "!python predict.py \\\n",
        "  --video_file /content/clip_343.mp4 \\\n",
        "  --tracknet_file ckpts/TrackNet_best.pt \\\n",
        "  --inpaintnet_file ckpts/InpaintNet_best.pt \\\n",
        "  --save_dir prediction \\\n",
        "  --output_video \\\n",
        "  --batch_size 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PAfiPDj7Z_U",
        "outputId": "64d7bd9e-2b2d-4a5a-c72b-78c2eacc9858"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/TrackNetV3\n",
            "ðŸš€ Starting inference...\n",
            "âœ… CSV saved: prediction/clip_343_ball.csv\n",
            "ðŸŽ¬ Generating output video...\n",
            "âœ… Video saved: prediction/clip_343.avi\n",
            "ðŸŽ‰ Done.\n"
          ]
        }
      ]
    }
  ]
}